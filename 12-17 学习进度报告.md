# 12/17 学习进度报告



---

## 项目环境搭建 ##
根据[videoavatars][1]中的指引配置即可，需要下载模型和数据集

## Step1 - Pose Reconstruction ##
1. 使用到的库简介
OpenCV - 有很多图像处理和计算机视觉有关的函数

        import cv2 


命令行解析和数据存储

    import h5py
    import argparse
    import cPickle as pkl

求导、微分、积分。。很多很多很强大的功能

    import numpy as np
    import chumpy as ch
   
  openDR
  
    from opendr.camera import ProjectPoints
    from opendr.lighting import LambertianPointLight
    from opendr.renderer import ColoredRenderer
    from opendr.filters import gaussian_pyramid
    
其他

    ...

2. 入口函数

        if __name__ == '__main__':
            parser = argparse.ArgumentParser()
            //这部分是在解析命令行中的输入参数，可以看help中的相关注释
            parser.add_argument(
            parser.add_argument(
                ... ...
            parser.add_argument(
       
            main(
            args.keypoint_file,//关节点文件，是预先通过OpenPose框架处理获取得到的，里面记录了人的18个关节点的位置坐标参考数据
            args.masks_file, //论文中提到的 silhouette image ，就是将每一帧中的人的形象截取进行二值化处理得到的图片，论文中有示意图
            args.camera,//相机文件
            args.out, //存储文件夹
            args.model, //在整个过程中被不断refine的基本人体模型
            args.prior, //这个是论文中提到的A-pose prior，但是具体是什么我没有理解到，姿势参考吗？。。。
            args.resize,//这个参数被用在keypoint_file的reshape了
            args.body_height, //论文中提到的身高
            args.nohands, //这个应该是个bool值，指计算的时候考不考虑手，不考虑的话计算关节点有关的数据时就会忽略手的数据
            args.display//这个应该就是跟展示有关的了)

keypoint_file可以看下这个[Github 项目 - OpenPose 关键点输出格式][2]

2. main函数

        def main(keypoint_file, masks_file, camera_file, out, model_file, prior_file, resize, body_height, nohands,display):

(1)加载数据
把预处理好的各种pkl和h5py数据加载进来
    
        model_data = pkl.load(fp)
        camera_data = pkl.load(fp)
        prior_data = pkl.load(fp)
            ...
        keypoints = h5py.File(keypoint_file, 'r')['keypoints']
        masks = h5py.File(masks_file, 'r')['masks']
        num_frames = masks.shape[0]

（2）初始化

        //将基本模型数据加载到一个Smpl对象里面
        base_smpl = Smpl(model_data)
        base_smpl.trans[:] = np.array([0, 0, 3])
        base_smpl.pose[0] = np.pi
        base_smpl.pose[3:] = prior_data['mean']//我觉得这一步可能就是把pose预设成A-pose prior的pose，从而在一个比较合理的基础上进一步改进
    
        //以下都是调用openDR里面的各种函数，我查了一下似乎是个跟openGL有点类似的库，我看着就有点怕就没细看了。。。
        camera = ProjectPoints(...)
        frustum = {...}
     ...
(3)创建frame对象的工具函数

    # generic frame loading function
    def create_frame(i, smpl, copy=True):
        f = FrameData()
        //存储了这一帧中的模型、相机、关节点、投影（？）、剪影等各种数据
        f.smpl =
        f.camera = 
        
这里我根据前后代码，暂时判断f.keypoint是一个shape（18,3）的数组，第i项是关节点i的x，y，scores，具体第几项是哪个关节的图我发群里了

        f.keypoints = np.array(keypoints[i]).reshape(-1, 3) * np.array([resize, resize, 1])
        //这两个不懂
        f.J = joints_coco(f.smpl)
        f.J_proj = ProjectPoints(v=f.J, t=camera.t, rt=camera.rt, c=camera.c, f=camera.f, k=camera.k)
        f.mask = 
        //以下也不是很清楚
        f.collision_obj = collision_obj(f.smpl, regs)
        f.pose_prior_obj = pose_prior_obj(f.smpl, prior_data)
        f.pose_obj = (f.J_proj - f.keypoints[:, :2]) * f.keypoints[:, 2].reshape(-1, 1)

        return f
（4）挑选5个帧的数据对模型进行一个预处理

    base_frame = create_frame(0, base_smpl, copy=False)//用最开始的一帧当做base

从所有帧里面等距挑选出5个来，组成init_frames数组

    num_init = 5
    indices_init = np.ceil(np.arange(num_init) * num_frames * 1. / num_init).astype(np.int)

    init_frames = [base_frame]
    for i in indices_init[1:]:
        init_frames.append(create_frame(i, base_smpl))
使用这5帧来预处理

        init(init_frames, body_height, b2m, debug_rn)

（5）逐帧对模型进行refine

    # get pose frame by frame
    with h5py.File(out, 'w') as fp:
        last_smpl = None
        poses_dset = 
        trans_dset = 
        betas_dset = 
        //以上是要写到out里的数据
        
        for i in xrange(num_frames):
           ......

re-init部分在论文中提到，每次循环都以前一帧的pose为基，当object error过大的时候，就进行re-init

            # re-init if necessary
            reinit_frame(current_frame, prior_data['mean'], nohands, debug_rn)
核心的fit函数

            # final fit
            fit_pose(current_frame, last_smpl, frustum, nohands, debug_rn)

存储每一帧相关的数据

            poses_dset[i] = current_frame.smpl.pose.r
            trans_dset[i] = current_frame.smpl.trans.r

            if i == 0:
                betas_dset[:] = current_frame.smpl.betas.r

            last_smpl = current_frame.smpl

    
    


  [1]: https://github.com/thmoa/videoavatars
  [2]: https://www.aiuai.cn/aifarm712.html